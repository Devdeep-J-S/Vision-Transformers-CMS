{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devdeep-J-S/Vision-Transformers-CMS/blob/main/Task_1_Electron_photon_classification_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name : Devdeep Shetranjiwala <br>\n",
        "Email ID : devdeep0702@gmail.com "
      ],
      "metadata": {
        "id": "3qXOJpKN31T_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1. Electron/photon classification\n",
        "Datasets:</br>\n",
        "https://cernbox.cern.ch/index.php/s/AtBT8y4MiQYFcgc (photons) </br>\n",
        "https://cernbox.cern.ch/index.php/s/FbXw3V4XNyYB3oA (electrons) </br>\n",
        "> Description: </br>\n",
        "32x32 matrices (two channels - hit energy and time) for two classes of particles electrons and photons impinging on a calorimeter\n",
        "Please use a deep learning method of your choice to achieve the highest possible\n",
        "classification on this dataset.\n",
        "\n",
        ">In this task, we will use deep learning to classify two classes of particles: electrons and photons impinging on a calorimeter. We will use two datasets, one for photons and one for electrons, which contains 32x32 matrices (two channels - hit energy and time) for each particle.</br>\n",
        "We will use deep learning framework PyTorch. Our goal is to achieve the highest possible classification accuracy on this dataset with a ROC AUC score of at least 0.80.\n",
        "</br>\n",
        "First, we will load the data and preprocess it.<br>\n",
        "Data Preprocessing : </br>\n",
        "We will load the datasets for photons and electrons and preprocess them. We will convert the data into numpy arrays and normalize them by dividing each pixel value by the maximum pixel value."
      ],
      "metadata": {
        "id": "Os4dmcA834Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import h5py\n",
        "\n",
        "from torchvision.transforms import CenterCrop\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-03-27T10:03:49.280622Z",
          "iopub.execute_input": "2023-03-27T10:03:49.281087Z",
          "iopub.status.idle": "2023-03-27T10:03:52.961965Z",
          "shell.execute_reply.started": "2023-03-27T10:03:49.281040Z",
          "shell.execute_reply": "2023-03-27T10:03:52.960935Z"
        },
        "trusted": true,
        "id": "Tv8ePPkq3QV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting Seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-27T10:03:52.964482Z",
          "iopub.execute_input": "2023-03-27T10:03:52.965362Z",
          "iopub.status.idle": "2023-03-27T10:03:52.973896Z",
          "shell.execute_reply.started": "2023-03-27T10:03:52.965321Z",
          "shell.execute_reply": "2023-03-27T10:03:52.972941Z"
        },
        "trusted": true,
        "id": "pqH-y4Lt3QV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting device to GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-27T10:03:52.975483Z",
          "iopub.execute_input": "2023-03-27T10:03:52.975841Z",
          "iopub.status.idle": "2023-03-27T10:03:53.043999Z",
          "shell.execute_reply.started": "2023-03-27T10:03:52.975804Z",
          "shell.execute_reply": "2023-03-27T10:03:53.042807Z"
        },
        "trusted": true,
        "id": "Tfa1lfql3QV5",
        "outputId": "a769ef7c-a11b-453c-c53d-c58bcdda7cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'cuda'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting data\n",
        "import requests\n",
        "url = 'https://cernbox.cern.ch/remote.php/dav/public-files/AtBT8y4MiQYFcgc/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('photons.hdf5', 'wb').write(r.content)\n",
        "url = 'https://cernbox.cern.ch/remote.php/dav/public-files/FbXw3V4XNyYB3oA/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('electrons.hdf5', 'wb').write(r.content)"
      ],
      "metadata": {
        "id": "xTJXAT4B4Quf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network\n",
        "class Net (nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv5 = nn.Conv2d(64, 128, kernel_size=1)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 64)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = torch.nn.functional.dropout(x, 0.2)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = torch.nn.functional.dropout(x, 0.2)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = torch.relu(x)\n",
        "        x = torch.nn.functional.dropout(x, 0.2)\n",
        "        x = self.pool3(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-27T10:03:53.046938Z",
          "iopub.execute_input": "2023-03-27T10:03:53.047297Z",
          "iopub.status.idle": "2023-03-27T10:03:53.063516Z",
          "shell.execute_reply.started": "2023-03-27T10:03:53.047260Z",
          "shell.execute_reply": "2023-03-27T10:03:53.062626Z"
        },
        "trusted": true,
        "id": "dLB2-cpR3QV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Dataset class\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, electrons_data, photons_data):\n",
        "        self.electrons_data = electrons_data\n",
        "        self.photons_data = photons_data\n",
        "        self.data_key = 'X'\n",
        "        self.file_electron = h5py.File(self.electrons_data, 'r')\n",
        "        self.data_electron = self.file_electron[self.data_key]\n",
        "        self.file_photon = h5py.File(self.photons_data, 'r')\n",
        "        self.data_photon = self.file_photon[self.data_key]\n",
        "        self.data = np.concatenate((self.data_electron, self.data_photon), axis=0)\n",
        "        self.labels = np.concatenate((np.ones(self.data_electron.shape[0]), np.zeros(self.data_photon.shape[0])), axis=0)\n",
        "        self.labels = np.expand_dims(self.labels, axis=1)\n",
        "        # wanted to try to normalize data \n",
        "        #self.data = (self.data - mean)/std\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.data[idx]), torch.from_numpy(self.labels[idx])\n",
        "\n",
        "    def close(self):\n",
        "        self.file_electrons.close()\n",
        "        self.file_photon.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-27T10:03:53.064912Z",
          "iopub.execute_input": "2023-03-27T10:03:53.065741Z",
          "iopub.status.idle": "2023-03-27T10:03:53.077293Z",
          "shell.execute_reply.started": "2023-03-27T10:03:53.065705Z",
          "shell.execute_reply": "2023-03-27T10:03:53.076445Z"
        },
        "trusted": true,
        "id": "PKxfu3mx3QV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making training, validation and test datasets\n",
        "# train data : 80%,\n",
        "# validation data : 10%,\n",
        "# testing data : 10%\n",
        "\n",
        "electrons_data = 'electrons.hdf5'\n",
        "photons_data = 'photons.hdf5'\n",
        "dataset = Dataset(electrons_data, photons_data)\n",
        "\n",
        "# Split the data into training, testing sets and validating sets \n",
        "train_size = np.int32(0.8 * len(dataset))\n",
        "test_size = np.int32(0.1 * len(dataset))\n",
        "val_size = len(dataset) - train_size - test_size\n",
        "\n",
        "train_data, test_data, val_data = random_split(dataset, [train_size, test_size, val_size])\n",
        "\n",
        "# Create the data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=200, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_data, batch_size=200, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_data, batch_size=200, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-27T10:03:53.078613Z",
          "iopub.execute_input": "2023-03-27T10:03:53.079129Z",
          "iopub.status.idle": "2023-03-27T10:04:10.222837Z",
          "shell.execute_reply.started": "2023-03-27T10:03:53.079094Z",
          "shell.execute_reply": "2023-03-27T10:04:10.221785Z"
        },
        "trusted": true,
        "id": "ASqe1n2d3QV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the loss function, optimizer \n",
        "model = Net().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.8)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-27T10:04:10.224664Z",
          "iopub.execute_input": "2023-03-27T10:04:10.225075Z",
          "iopub.status.idle": "2023-03-27T10:04:13.021801Z",
          "shell.execute_reply.started": "2023-03-27T10:04:10.225034Z",
          "shell.execute_reply": "2023-03-27T10:04:13.020778Z"
        },
        "trusted": true,
        "id": "EbHuv_JP3QV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "epochs = 200 # takes time but gives good result \n",
        "min_val_loss = np.inf\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_aucs = []\n",
        "val_aucs = []\n",
        "counter = 0\n",
        "\n",
        "for e in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    train_auc = 0.0\n",
        "    i = 0\n",
        "    for data in train_loader: # Training Loop\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        #print(inputs.shape)\n",
        "        outputs = model(inputs)\n",
        "        labels , outputs = labels.type(torch.FloatTensor),outputs.type(torch.FloatTensor)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        with torch.no_grad():\n",
        "            train_auc += roc_auc_score(labels.numpy(), outputs.numpy())\n",
        "        \n",
        "        if i % 100 == 99:    # save every 100 mini-batches\n",
        "            train_losses.append(train_loss / 100)\n",
        "            train_aucs.append(train_auc / 100)\n",
        "            train_loss = 0.0\n",
        "            train_auc = 0.0\n",
        "        \n",
        "        i += 1\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        val_auc = 0.0\n",
        "        model.eval()\n",
        "        for data in val_loader: # Validation Loop\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            labels , outputs = labels.type(torch.FloatTensor),outputs.type(torch.FloatTensor)\n",
        "            loss = criterion(outputs,labels)\n",
        "            val_loss += loss.item()\n",
        "            val_auc += roc_auc_score(labels.numpy(), outputs.numpy())\n",
        "        \n",
        "    print(f'Epoch {e+1} Val Loss: {val_loss / len(val_loader)} \\t\\t Val Accuracy: {val_auc / len(val_loader)}')\n",
        "    \n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_aucs.append(val_auc / len(val_loader))\n",
        "     \n",
        "    # basic need for task - 1 AUC ROC SCORE    \n",
        "#     if (val_auc / len(val_loader)>=0.85) :\n",
        "#         break\n",
        "        \n",
        "    if min_val_loss > val_loss:\n",
        "        print(f'Validation Loss Decreased({min_val_loss:.6f}--->{val_loss:.6f}) \\t Saving The Model')\n",
        "        min_val_loss = val_loss\n",
        "        counter = 0 \n",
        "            \n",
        "        # Saving the model\n",
        "        torch.save(model.state_dict(), 'saved_model.pth')\n",
        "        \n",
        "    else:\n",
        "        # Early Stopping\n",
        "        counter += 1\n",
        "        if counter >= 20:\n",
        "            print('Training Stopped.')\n",
        "            break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-27T10:12:29.011356Z",
          "iopub.execute_input": "2023-03-27T10:12:29.012222Z",
          "iopub.status.idle": "2023-03-27T13:16:19.987105Z",
          "shell.execute_reply.started": "2023-03-27T10:12:29.012184Z",
          "shell.execute_reply": "2023-03-27T13:16:19.985734Z"
        },
        "trusted": true,
        "id": "w2y474na3QV_",
        "outputId": "eb73b7a3-0f44-4684-ad05-ebf3ec45fc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1 Val Loss: 0.6072167335265133 \t\t Val Accuracy: 0.7369851546367092\nValidation Loss Decreased(inf--->151.196967) \t Saving The Model\nEpoch 2 Val Loss: 0.6081583854185051 \t\t Val Accuracy: 0.740356061553586\nEpoch 3 Val Loss: 0.5914301632877335 \t\t Val Accuracy: 0.7503892535118144\nValidation Loss Decreased(151.196967--->147.266111) \t Saving The Model\nEpoch 4 Val Loss: 0.600578661424568 \t\t Val Accuracy: 0.7381515964134102\nEpoch 5 Val Loss: 0.5842341525727007 \t\t Val Accuracy: 0.7579935904893578\nValidation Loss Decreased(147.266111--->145.474304) \t Saving The Model\nEpoch 6 Val Loss: 0.5934161859822561 \t\t Val Accuracy: 0.7548254557609606\nEpoch 7 Val Loss: 0.5819701387221554 \t\t Val Accuracy: 0.7637875211259614\nValidation Loss Decreased(145.474304--->144.910565) \t Saving The Model\nEpoch 8 Val Loss: 0.5812393273694448 \t\t Val Accuracy: 0.7645595698981348\nValidation Loss Decreased(144.910565--->144.728593) \t Saving The Model\nEpoch 9 Val Loss: 0.5788110372531845 \t\t Val Accuracy: 0.7652007781786321\nValidation Loss Decreased(144.728593--->144.123948) \t Saving The Model\nEpoch 10 Val Loss: 0.57970071341618 \t\t Val Accuracy: 0.7666604812819116\nEpoch 11 Val Loss: 0.5755691753333831 \t\t Val Accuracy: 0.7679217511111103\nValidation Loss Decreased(144.123948--->143.316725) \t Saving The Model\nEpoch 12 Val Loss: 0.5708940789163353 \t\t Val Accuracy: 0.772955152918326\nValidation Loss Decreased(143.316725--->142.152626) \t Saving The Model\nEpoch 13 Val Loss: 0.5771601701596655 \t\t Val Accuracy: 0.7721761164428127\nEpoch 14 Val Loss: 0.5742615105876003 \t\t Val Accuracy: 0.7717848550599461\nEpoch 15 Val Loss: 0.5729399172656507 \t\t Val Accuracy: 0.7720169070709292\nEpoch 16 Val Loss: 0.5681727051016796 \t\t Val Accuracy: 0.7758303530510955\nValidation Loss Decreased(142.152626--->141.475004) \t Saving The Model\nEpoch 17 Val Loss: 0.5692711361201412 \t\t Val Accuracy: 0.775288075208234\nEpoch 18 Val Loss: 0.5632378049643643 \t\t Val Accuracy: 0.7802353137509261\nValidation Loss Decreased(141.475004--->140.246213) \t Saving The Model\nEpoch 19 Val Loss: 0.5658256288273746 \t\t Val Accuracy: 0.7778272929789806\nEpoch 20 Val Loss: 0.5722388421675287 \t\t Val Accuracy: 0.7759157862184276\nEpoch 21 Val Loss: 0.5653194252506317 \t\t Val Accuracy: 0.7784003965847642\nEpoch 22 Val Loss: 0.5635452829450968 \t\t Val Accuracy: 0.7800464385111475\nEpoch 23 Val Loss: 0.5628212647265699 \t\t Val Accuracy: 0.7810200951661862\nValidation Loss Decreased(140.246213--->140.142495) \t Saving The Model\nEpoch 24 Val Loss: 0.5665067813722006 \t\t Val Accuracy: 0.7772758021496893\nEpoch 25 Val Loss: 0.5604754581030114 \t\t Val Accuracy: 0.7829288498297073\nValidation Loss Decreased(140.142495--->139.558389) \t Saving The Model\nEpoch 26 Val Loss: 0.5662742034498468 \t\t Val Accuracy: 0.7811252167960143\nEpoch 27 Val Loss: 0.5661287434608582 \t\t Val Accuracy: 0.776744856420648\nEpoch 28 Val Loss: 0.563333258810771 \t\t Val Accuracy: 0.7808372050480276\nEpoch 29 Val Loss: 0.5618171416612036 \t\t Val Accuracy: 0.7834433635004471\nEpoch 30 Val Loss: 0.5601869692285377 \t\t Val Accuracy: 0.7843426015591506\nValidation Loss Decreased(139.558389--->139.486555) \t Saving The Model\nEpoch 31 Val Loss: 0.5614525851715042 \t\t Val Accuracy: 0.7830695119366444\nEpoch 32 Val Loss: 0.56464904343268 \t\t Val Accuracy: 0.7806838786327736\nEpoch 33 Val Loss: 0.5560201278412678 \t\t Val Accuracy: 0.7871157355751278\nValidation Loss Decreased(139.486555--->138.449012) \t Saving The Model\nEpoch 34 Val Loss: 0.5574087534084856 \t\t Val Accuracy: 0.7872656919887278\nEpoch 35 Val Loss: 0.5598642514891414 \t\t Val Accuracy: 0.7851876514740206\nEpoch 36 Val Loss: 0.5596227503445254 \t\t Val Accuracy: 0.7865980354471361\nEpoch 37 Val Loss: 0.5594058689104027 \t\t Val Accuracy: 0.7849425328545718\nEpoch 38 Val Loss: 0.5602379547783649 \t\t Val Accuracy: 0.7873709362934163\nEpoch 39 Val Loss: 0.5606001039824812 \t\t Val Accuracy: 0.7842565084936277\nEpoch 40 Val Loss: 0.5544772454533711 \t\t Val Accuracy: 0.7893949849190912\nValidation Loss Decreased(138.449012--->138.064834) \t Saving The Model\nEpoch 41 Val Loss: 0.5615286855812532 \t\t Val Accuracy: 0.7857096780097315\nEpoch 42 Val Loss: 0.5547835898686604 \t\t Val Accuracy: 0.7891461732074977\nEpoch 43 Val Loss: 0.5579593055937664 \t\t Val Accuracy: 0.7875759980505621\nEpoch 44 Val Loss: 0.5536967803196735 \t\t Val Accuracy: 0.7905988124290759\nValidation Loss Decreased(138.064834--->137.870498) \t Saving The Model\nEpoch 45 Val Loss: 0.5548423807544401 \t\t Val Accuracy: 0.7890263193817489\nEpoch 46 Val Loss: 0.5532090175582702 \t\t Val Accuracy: 0.7906870422088842\nValidation Loss Decreased(137.870498--->137.749045) \t Saving The Model\nEpoch 47 Val Loss: 0.551823615788456 \t\t Val Accuracy: 0.7913949235727069\nValidation Loss Decreased(137.749045--->137.404080) \t Saving The Model\nEpoch 48 Val Loss: 0.5552902398817989 \t\t Val Accuracy: 0.7889332470742472\nEpoch 49 Val Loss: 0.5509715440522236 \t\t Val Accuracy: 0.7929410748884489\nValidation Loss Decreased(137.404080--->137.191914) \t Saving The Model\nEpoch 50 Val Loss: 0.5599430213012848 \t\t Val Accuracy: 0.7862640177677204\nEpoch 51 Val Loss: 0.5553564818269278 \t\t Val Accuracy: 0.7879640720303269\nEpoch 52 Val Loss: 0.5533078248242298 \t\t Val Accuracy: 0.790961877167009\nEpoch 53 Val Loss: 0.5510819677607601 \t\t Val Accuracy: 0.793819437526973\nEpoch 54 Val Loss: 0.5491095867501684 \t\t Val Accuracy: 0.7948023969771705\nValidation Loss Decreased(137.191914--->136.728287) \t Saving The Model\nEpoch 55 Val Loss: 0.5542238871735262 \t\t Val Accuracy: 0.7920002021426027\nEpoch 56 Val Loss: 0.5540607851671885 \t\t Val Accuracy: 0.7926925465637594\nEpoch 57 Val Loss: 0.5586805237105572 \t\t Val Accuracy: 0.7915490703203594\nEpoch 58 Val Loss: 0.5522291061868629 \t\t Val Accuracy: 0.7909825558336883\nEpoch 59 Val Loss: 0.5536317725976309 \t\t Val Accuracy: 0.791813017332504\nEpoch 60 Val Loss: 0.5509639117851793 \t\t Val Accuracy: 0.7932795228280101\nEpoch 61 Val Loss: 0.5488814898284085 \t\t Val Accuracy: 0.7943622201409652\nValidation Loss Decreased(136.728287--->136.671491) \t Saving The Model\nEpoch 62 Val Loss: 0.5539373347318794 \t\t Val Accuracy: 0.7934323168531511\nEpoch 63 Val Loss: 0.5554737137503414 \t\t Val Accuracy: 0.7890231694629167\nEpoch 64 Val Loss: 0.5503094555383705 \t\t Val Accuracy: 0.7949597994877232\nEpoch 65 Val Loss: 0.54909282479899 \t\t Val Accuracy: 0.796323277858574\nEpoch 66 Val Loss: 0.5488084126189052 \t\t Val Accuracy: 0.7946651847460203\nValidation Loss Decreased(136.671491--->136.653295) \t Saving The Model\nEpoch 67 Val Loss: 0.552268603958758 \t\t Val Accuracy: 0.7918372287297116\nEpoch 68 Val Loss: 0.5471031270831465 \t\t Val Accuracy: 0.7963583213446038\nValidation Loss Decreased(136.653295--->136.228679) \t Saving The Model\nEpoch 69 Val Loss: 0.5486813665154469 \t\t Val Accuracy: 0.7941641678449053\nEpoch 70 Val Loss: 0.5534806477736278 \t\t Val Accuracy: 0.7932121882230542\nEpoch 71 Val Loss: 0.5492884612466437 \t\t Val Accuracy: 0.7957704804938063\nEpoch 72 Val Loss: 0.5500988726874432 \t\t Val Accuracy: 0.7951950553971937\nEpoch 73 Val Loss: 0.5463436036464201 \t\t Val Accuracy: 0.7966609653803394\nValidation Loss Decreased(136.228679--->136.039557) \t Saving The Model\nEpoch 74 Val Loss: 0.5502901565597718 \t\t Val Accuracy: 0.7956635674809804\nEpoch 75 Val Loss: 0.5463940573025898 \t\t Val Accuracy: 0.7976926218882002\nEpoch 76 Val Loss: 0.5498145846238577 \t\t Val Accuracy: 0.7939793907418021\nEpoch 77 Val Loss: 0.547870142153468 \t\t Val Accuracy: 0.7954288318352085\nEpoch 78 Val Loss: 0.5486669311801113 \t\t Val Accuracy: 0.7951280335239711\nEpoch 79 Val Loss: 0.5579696082207094 \t\t Val Accuracy: 0.7916047021364552\nEpoch 80 Val Loss: 0.5435890096976576 \t\t Val Accuracy: 0.7990652135810219\nValidation Loss Decreased(136.039557--->135.353663) \t Saving The Model\nEpoch 81 Val Loss: 0.5471631761296207 \t\t Val Accuracy: 0.7965416909685112\nEpoch 82 Val Loss: 0.5465099015628477 \t\t Val Accuracy: 0.7974240666673633\nEpoch 83 Val Loss: 0.5490827853660507 \t\t Val Accuracy: 0.7971313369292102\nEpoch 84 Val Loss: 0.552619075679396 \t\t Val Accuracy: 0.7924731653017879\nEpoch 85 Val Loss: 0.5459773471077762 \t\t Val Accuracy: 0.7974210618893576\nEpoch 86 Val Loss: 0.5459741634058665 \t\t Val Accuracy: 0.7979919688288144\nEpoch 87 Val Loss: 0.547325289871798 \t\t Val Accuracy: 0.7956925068785714\nEpoch 88 Val Loss: 0.5486206241161469 \t\t Val Accuracy: 0.7963201817506046\nEpoch 89 Val Loss: 0.5441504472709564 \t\t Val Accuracy: 0.7988325699428362\nEpoch 90 Val Loss: 0.5432127673463171 \t\t Val Accuracy: 0.7997780787156075\nValidation Loss Decreased(135.353663--->135.259979) \t Saving The Model\nEpoch 91 Val Loss: 0.5507725414980846 \t\t Val Accuracy: 0.7975458469629182\nEpoch 92 Val Loss: 0.5451186544684521 \t\t Val Accuracy: 0.7983876271184818\nEpoch 93 Val Loss: 0.5435707248358362 \t\t Val Accuracy: 0.7999792324613776\nEpoch 94 Val Loss: 0.5440631664421663 \t\t Val Accuracy: 0.7989747040582595\nEpoch 95 Val Loss: 0.5506150795513367 \t\t Val Accuracy: 0.793918734119664\nEpoch 96 Val Loss: 0.5447543131778518 \t\t Val Accuracy: 0.798523968757935\nEpoch 97 Val Loss: 0.5444216291349097 \t\t Val Accuracy: 0.7987665003514922\nEpoch 98 Val Loss: 0.5429947424126438 \t\t Val Accuracy: 0.8003196392163822\nValidation Loss Decreased(135.259979--->135.205691) \t Saving The Model\nEpoch 99 Val Loss: 0.5434152144026086 \t\t Val Accuracy: 0.7998955599857424\nEpoch 100 Val Loss: 0.5479928755377191 \t\t Val Accuracy: 0.7987572783264381\nEpoch 101 Val Loss: 0.5434252987185635 \t\t Val Accuracy: 0.7995108796509299\nEpoch 102 Val Loss: 0.5436309410865048 \t\t Val Accuracy: 0.8005066888760752\nEpoch 103 Val Loss: 0.5456557466562493 \t\t Val Accuracy: 0.7993690255128586\nEpoch 104 Val Loss: 0.5442182991399344 \t\t Val Accuracy: 0.799690623427624\nEpoch 105 Val Loss: 0.5437312808381506 \t\t Val Accuracy: 0.7996385198059367\nEpoch 106 Val Loss: 0.5438162975282554 \t\t Val Accuracy: 0.8006004636720778\nEpoch 107 Val Loss: 0.5446193883696713 \t\t Val Accuracy: 0.7996048067121134\nEpoch 108 Val Loss: 0.5449816524743076 \t\t Val Accuracy: 0.8004485400622667\nEpoch 109 Val Loss: 0.5425583464074805 \t\t Val Accuracy: 0.8008658828947387\nValidation Loss Decreased(135.205691--->135.097028) \t Saving The Model\nEpoch 110 Val Loss: 0.5418022716619882 \t\t Val Accuracy: 0.8010110653428814\nValidation Loss Decreased(135.097028--->134.908766) \t Saving The Model\nEpoch 111 Val Loss: 0.5481426007297623 \t\t Val Accuracy: 0.796777538330923\nEpoch 112 Val Loss: 0.5422392495904103 \t\t Val Accuracy: 0.8005136268851132\nEpoch 113 Val Loss: 0.5471664896930557 \t\t Val Accuracy: 0.7988482250751664\nEpoch 114 Val Loss: 0.5419716951119373 \t\t Val Accuracy: 0.8008111687969681\nEpoch 115 Val Loss: 0.5421704361477051 \t\t Val Accuracy: 0.8008548722283753\nEpoch 116 Val Loss: 0.5440301757500353 \t\t Val Accuracy: 0.8012869699931994\nEpoch 117 Val Loss: 0.5419068623738117 \t\t Val Accuracy: 0.8011014252145348\nEpoch 118 Val Loss: 0.5403775511735893 \t\t Val Accuracy: 0.8015702623705115\nValidation Loss Decreased(134.908766--->134.554010) \t Saving The Model\nEpoch 119 Val Loss: 0.5445032192760682 \t\t Val Accuracy: 0.798902460855946\nEpoch 120 Val Loss: 0.5418781277884441 \t\t Val Accuracy: 0.8019421454174165\nEpoch 121 Val Loss: 0.5461475211214349 \t\t Val Accuracy: 0.8008584215404588\nEpoch 122 Val Loss: 0.5446651758678467 \t\t Val Accuracy: 0.7987802875450409\nEpoch 123 Val Loss: 0.542019715510219 \t\t Val Accuracy: 0.8019373856528804\nEpoch 124 Val Loss: 0.5422930437398245 \t\t Val Accuracy: 0.8011130578682756\nEpoch 125 Val Loss: 0.5425454135161327 \t\t Val Accuracy: 0.8002590976443041\nEpoch 126 Val Loss: 0.5425348413517197 \t\t Val Accuracy: 0.8008960365165013\nEpoch 127 Val Loss: 0.5419042321094069 \t\t Val Accuracy: 0.8016338316719579\nEpoch 128 Val Loss: 0.5412611666932163 \t\t Val Accuracy: 0.8014828641114063\nEpoch 129 Val Loss: 0.5408807967800692 \t\t Val Accuracy: 0.8026792388251707\nEpoch 130 Val Loss: 0.5479325045304126 \t\t Val Accuracy: 0.7959223178314737\nEpoch 131 Val Loss: 0.540656698396407 \t\t Val Accuracy: 0.8019421958012173\nEpoch 132 Val Loss: 0.5419903063630483 \t\t Val Accuracy: 0.8007079053818065\nEpoch 133 Val Loss: 0.5411662948897564 \t\t Val Accuracy: 0.8020616996100395\nEpoch 134 Val Loss: 0.5415161696064424 \t\t Val Accuracy: 0.8017890334493841\nEpoch 135 Val Loss: 0.5418746952550957 \t\t Val Accuracy: 0.8017071168050216\nEpoch 136 Val Loss: 0.5401937995091021 \t\t Val Accuracy: 0.8019535849055458\nValidation Loss Decreased(134.554010--->134.508256) \t Saving The Model\nEpoch 137 Val Loss: 0.5410854903809038 \t\t Val Accuracy: 0.8016166115176938\nEpoch 138 Val Loss: 0.5404421925305363 \t\t Val Accuracy: 0.8025713305898755\nEpoch 139 Val Loss: 0.539483884730971 \t\t Val Accuracy: 0.8029643490146431\nValidation Loss Decreased(134.508256--->134.331487) \t Saving The Model\nEpoch 140 Val Loss: 0.5409936641593535 \t\t Val Accuracy: 0.8031312776366267\nEpoch 141 Val Loss: 0.539796689188624 \t\t Val Accuracy: 0.8032585010611509\nEpoch 142 Val Loss: 0.5433084883364329 \t\t Val Accuracy: 0.8003947186449506\nEpoch 143 Val Loss: 0.5401424138421514 \t\t Val Accuracy: 0.8025408459124364\nEpoch 144 Val Loss: 0.5412057852409929 \t\t Val Accuracy: 0.8013703334315806\nEpoch 145 Val Loss: 0.5391651543986845 \t\t Val Accuracy: 0.8033985036546101\nValidation Loss Decreased(134.331487--->134.252123) \t Saving The Model\nEpoch 146 Val Loss: 0.5411269231493693 \t\t Val Accuracy: 0.8029710581286199\nEpoch 147 Val Loss: 0.5389605515213856 \t\t Val Accuracy: 0.8037414160758705\nValidation Loss Decreased(134.252123--->134.201177) \t Saving The Model\nEpoch 148 Val Loss: 0.5385785791050478 \t\t Val Accuracy: 0.8039301387250876\nValidation Loss Decreased(134.201177--->134.106066) \t Saving The Model\nEpoch 149 Val Loss: 0.5386352916079832 \t\t Val Accuracy: 0.8042345842758178\nEpoch 150 Val Loss: 0.5393852559198816 \t\t Val Accuracy: 0.8033927363106489\nEpoch 151 Val Loss: 0.5401578314572453 \t\t Val Accuracy: 0.8029361446459983\nEpoch 152 Val Loss: 0.5394743629488121 \t\t Val Accuracy: 0.8032579291621142\nEpoch 153 Val Loss: 0.5389294193451664 \t\t Val Accuracy: 0.8029245585821578\nEpoch 154 Val Loss: 0.5388284866589619 \t\t Val Accuracy: 0.803953710084886\nEpoch 155 Val Loss: 0.5394690258196558 \t\t Val Accuracy: 0.802977102594302\nEpoch 156 Val Loss: 0.5391070788883301 \t\t Val Accuracy: 0.803405083201045\nEpoch 157 Val Loss: 0.5395317518088713 \t\t Val Accuracy: 0.8030079367605725\nEpoch 158 Val Loss: 0.5409737165912567 \t\t Val Accuracy: 0.8027854759267059\nEpoch 159 Val Loss: 0.5413098846334051 \t\t Val Accuracy: 0.8019477851859811\nEpoch 160 Val Loss: 0.5464323723172567 \t\t Val Accuracy: 0.7995118602896795\nEpoch 161 Val Loss: 0.5381207226749405 \t\t Val Accuracy: 0.8044785374359396\nValidation Loss Decreased(134.106066--->133.992060) \t Saving The Model\nEpoch 162 Val Loss: 0.5409473373468621 \t\t Val Accuracy: 0.8022029597780724\nEpoch 163 Val Loss: 0.5390406970278805 \t\t Val Accuracy: 0.8040416822331017\nEpoch 164 Val Loss: 0.5397855160705536 \t\t Val Accuracy: 0.8031397950390577\nEpoch 165 Val Loss: 0.5422663562987224 \t\t Val Accuracy: 0.8012166130611782\nEpoch 166 Val Loss: 0.5389690734296438 \t\t Val Accuracy: 0.8038128338075441\nEpoch 167 Val Loss: 0.5405272846241074 \t\t Val Accuracy: 0.803631937965966\nEpoch 168 Val Loss: 0.5403668824209267 \t\t Val Accuracy: 0.8032395928838816\nEpoch 169 Val Loss: 0.5382595525448581 \t\t Val Accuracy: 0.8040823176775677\nEpoch 170 Val Loss: 0.5403155205718964 \t\t Val Accuracy: 0.8036169962006562\nEpoch 171 Val Loss: 0.5381770964607178 \t\t Val Accuracy: 0.8039606861984997\nEpoch 172 Val Loss: 0.5395261715933022 \t\t Val Accuracy: 0.8033569778577089\nEpoch 173 Val Loss: 0.5392816391096537 \t\t Val Accuracy: 0.8050212978607125\nEpoch 174 Val Loss: 0.5412740672687929 \t\t Val Accuracy: 0.8044511703401473\nEpoch 175 Val Loss: 0.5399958820467493 \t\t Val Accuracy: 0.8038542720628452\nEpoch 176 Val Loss: 0.5386090101487186 \t\t Val Accuracy: 0.8049632324604314\nEpoch 177 Val Loss: 0.5383178019619371 \t\t Val Accuracy: 0.8047474655726518\nEpoch 178 Val Loss: 0.5381267623729017 \t\t Val Accuracy: 0.8043545799264975\nEpoch 179 Val Loss: 0.539576028484896 \t\t Val Accuracy: 0.8041004291718947\nEpoch 180 Val Loss: 0.5395186196369339 \t\t Val Accuracy: 0.8037332392317453\nEpoch 181 Val Loss: 0.5388431030823045 \t\t Val Accuracy: 0.8038766250458411\nTraining Stopped.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance on test set\n",
        "trained_model = Net().to(device)\n",
        "\n",
        "trained_model.load_state_dict(torch.load('saved_model.pth'))\n",
        "trained_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_loss = 0.0\n",
        "    test_auc = 0.0\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = trained_model(inputs)\n",
        "        labels , outputs = labels.type(torch.FloatTensor),outputs.type(torch.FloatTensor)\n",
        "        loss = criterion(outputs,labels)\n",
        "        test_loss += loss.item()\n",
        "        test_auc += roc_auc_score(labels.numpy(), outputs.numpy())\n",
        "\n",
        "print(f\"The loss on testing data is {test_loss/len(test_loader)} and the ROC-AUC is {test_auc/len(test_loader)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-27T13:17:54.818746Z",
          "iopub.execute_input": "2023-03-27T13:17:54.819184Z",
          "iopub.status.idle": "2023-03-27T13:17:57.846922Z",
          "shell.execute_reply.started": "2023-03-27T13:17:54.819141Z",
          "shell.execute_reply": "2023-03-27T13:17:57.845723Z"
        },
        "trusted": true,
        "id": "axm7CtzL3QWA",
        "outputId": "73a94d3a-4d89-424b-9f89-1da87d007aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "The loss on testing data is 0.5423456724867763 and the ROC-AUC is 0.8003556647834663\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best ROC AUC score (validate) : 0.8083 </br>\n",
        "Best ROC AUC score (test) : 0.8004 </br>"
      ],
      "metadata": {
        "id": "UvOyr4L_4uj4"
      }
    }
  ]
}